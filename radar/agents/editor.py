"""
Editor Agent (Executive Synthesizer) for Tubi Radar.

Responsible for producing the final daily/weekly radar report
from intel and annotations.
"""
from __future__ import annotations

from datetime import datetime
from typing import Optional

from langchain_core.messages import SystemMessage, HumanMessage

from radar.agents.base import BaseAgent
from radar.config import get_config
from radar.schemas import ReportStructure
from radar.tools.db_tools import get_all_intel_for_run, create_report_file


class EditorAgent(BaseAgent):
    """
    The Editor Agent synthesizes intel into a human-readable report.
    
    Produces a Markdown report organized by:
    1. Top Moves (3-5 key items)
    2. Product & UX section
    3. Content & Library section
    4. Marketing & Positioning section
    5. AI & Ads / Pricing section
    6. Suggested Actions
    """
    
    agent_role = "editor_agent"
    system_prompt = """You are the Executive Editor for Tubi Radar, generating a competitive intelligence digest for senior product, content, and marketing leaders at Tubi.

Tubi is a free ad-supported streaming television (FAST) service. Your audience needs to understand what competitors are doing and how it might affect Tubi's strategy.

You will be given structured intel and agent annotations. Your goals:

1. **Top Moves**: Highlight 3-5 key moves Tubi should care about most. These are the headlines.

2. **Organize by Section**: Group remaining intel into:
   - Product & UX: Platform features, apps, devices, technology
   - Content & Library: Shows, movies, content deals, originals
   - Marketing & Positioning: Campaigns, branding, partnerships
   - AI & Ads / Pricing: Ad tech, pricing, monetization

3. **Writing Style**:
   - Be clear, concise, without hype or filler
   - Include competitor names and dates
   - Focus on "so what" for Tubi
   - Highlight risks and opportunities where relevant

4. **Suggested Actions**: Surface actionable next steps where they add value.

Output clean, professional Markdown suitable for executives."""

    @property
    def temperature(self) -> float:
        """Use higher temperature for more creative report writing."""
        if self._temperature_override is not None:
            return self._temperature_override
        return self.config.global_config.temperature.report
    
    def _build_intel_prompt(self, intel_items: list[dict]) -> str:
        """Build the prompt with intel data."""
        if not intel_items:
            return "No significant intel to report for this period."
        
        lines = [f"Today's date: {datetime.utcnow().strftime('%Y-%m-%d')}\n"]
        lines.append(f"Total intel items: {len(intel_items)}\n")
        lines.append("---\n")
        
        for item in intel_items:
            lines.append(f"**Intel #{item['id']}**")
            lines.append(f"- Competitor: {item['competitor_id']}")
            lines.append(f"- Category: {item['category']}")
            lines.append(f"- Impact: {item['impact_score']}/10 | Relevance: {item['relevance_score']}/10")
            lines.append(f"- Title: {item['title']}")
            lines.append(f"- Summary: {item['summary']}")
            
            if item.get('annotations'):
                lines.append("\nAgent Perspectives:")
                for ann in item['annotations']:
                    lines.append(f"  - [{ann['agent_role']}] {ann['priority']}: {ann['so_what']}")
                    if ann.get('suggested_action'):
                        lines.append(f"    â†’ Action: {ann['suggested_action']}")
            
            lines.append("")
        
        lines.append("---\nGenerate the executive report based on this intel.")
        return "\n".join(lines)
    
    def _generate_report_markdown(self, intel_items: list[dict]) -> str:
        """
        Generate the report using the LLM.
        
        Args:
            intel_items: List of intel dictionaries with annotations
        
        Returns:
            Markdown report content
        """
        config = get_config()
        date_str = datetime.utcnow().strftime("%Y-%m-%d")
        
        # Handle empty case
        if not intel_items:
            return f"""# Tubi Radar - {date_str}

## Executive Summary

No significant competitive intelligence to report for this period.

All monitored feeds were checked, but no items met the relevance and impact thresholds.

---
*Report generated by Tubi Radar*
"""
        
        # For Phase 1, generate a simpler report without full structured output
        # Phase 2 will use ReportStructure for more structured generation
        
        llm = self.get_llm()
        
        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=self._build_intel_prompt(intel_items)),
        ]
        
        try:
            response = llm.invoke(messages)
            report_content = response.content
            
            # Ensure title is present
            if not report_content.strip().startswith("#"):
                report_content = f"# Tubi Radar - {date_str}\n\n{report_content}"
            
            # Add footer
            report_content += f"\n\n---\n*Report generated by Tubi Radar on {date_str}*\n"
            
            return report_content
        except Exception as e:
            print(f"[EditorAgent] Error generating report: {e}")
            return f"""# Tubi Radar - {date_str}

## Error

Failed to generate report: {str(e)}

---
*Report generated by Tubi Radar*
"""
    
    def run(
        self,
        run_id: int,
        min_relevance: Optional[float] = None,
        min_impact: Optional[float] = None,
    ) -> dict:
        """
        Execute the report generation process.
        
        Args:
            run_id: The current run ID
            min_relevance: Minimum relevance score (uses config default if None)
            min_impact: Minimum impact score (uses config default if None)
        
        Returns:
            Dictionary with report generation results
        """
        config = get_config()
        
        min_relevance = min_relevance or config.global_config.min_relevance_score
        min_impact = min_impact or config.global_config.min_impact_score
        
        # Get all qualifying intel with annotations
        intel_items = get_all_intel_for_run(
            run_id=run_id,
            min_relevance=min_relevance,
            min_impact=min_impact,
        )
        
        # Limit to max report items
        intel_items = intel_items[:config.global_config.max_report_items]
        
        print(f"[EditorAgent] Generating report from {len(intel_items)} intel items...")
        
        # Generate report
        report_markdown = self._generate_report_markdown(intel_items)
        
        # Save report
        report_path = create_report_file.invoke({
            "run_id": run_id,
            "content_markdown": report_markdown,
        })
        
        print(f"[EditorAgent] Report saved to: {report_path}")
        
        return {
            "intel_items_included": len(intel_items),
            "report_path": report_path,
            "report_length": len(report_markdown),
        }


def run_editor(run_id: int) -> dict:
    """
    Convenience function to run the Editor Agent.
    
    Args:
        run_id: The current run ID
    
    Returns:
        Editor results
    """
    agent = EditorAgent()
    return agent.run(run_id=run_id)

